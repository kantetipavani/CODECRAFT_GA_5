{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "!pip install -q gradio pillow numpy opencv-python\n",
        "\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "import cv2\n",
        "import gradio as gr\n",
        "import os\n",
        "\n",
        "\n",
        "def blend_images(img1, img2, alpha=0.5, size=512):\n",
        "    i1 = img1.convert(\"RGB\").resize((size,size), Image.LANCZOS)\n",
        "    i2 = img2.convert(\"RGB\").resize((size,size), Image.LANCZOS)\n",
        "    return Image.blend(i1, i2, alpha)\n",
        "\n",
        "def sharpen_image(pil_img, amount=1.5):\n",
        "    img = np.array(pil_img, dtype=np.float32)\n",
        "    blur = cv2.GaussianBlur(img, (0,0), sigmaX=3)\n",
        "    sharp = cv2.addWeighted(img, 1+amount, blur, -amount, 0)\n",
        "    return Image.fromarray(np.clip(sharp,0,255).astype(np.uint8))\n",
        "\n",
        "def apply_mask(img, mask_path, size=512):\n",
        "    \"\"\"\n",
        "    Apply a white-on-black mask to the image.\n",
        "    White = keep, Black = transparent (background)\n",
        "    \"\"\"\n",
        "    img = img.convert(\"RGBA\").resize((size,size), Image.LANCZOS)\n",
        "    mask = Image.open(mask_path).convert(\"L\").resize((size,size), Image.LANCZOS)\n",
        "    img.putalpha(mask)\n",
        "    return img\n",
        "\n",
        "\n",
        "def fuse_images_with_shape(img1, img2, attribute, alpha=0.5, sharpen_amt=1.5):\n",
        "    # Map attribute to mask file\n",
        "    mask_map = {\n",
        "        \"boy kurthys\": \"masks/boy_kurthys_mask.png\",\n",
        "        \"sheets\": \"masks/sheets_mask.png\",\n",
        "        \"t-shirts\": \"masks/tshirts_mask.png\",\n",
        "        \"women lehenga\": \"masks/women_lehenga_mask.png\",\n",
        "        \"sarees\": \"masks/sarees_mask.png\",\n",
        "        \"tops\": \"masks/tops_mask.png\",\n",
        "        \"night dress\": \"masks/nightdress_mask.png\"\n",
        "    }\n",
        "\n",
        "\n",
        "    if attribute in mask_map and os.path.exists(mask_map[attribute]):\n",
        "        img1_masked = apply_mask(img1, mask_map[attribute])\n",
        "        img2_masked = apply_mask(img2, mask_map[attribute])\n",
        "    else:\n",
        "        img1_masked = img1\n",
        "        img2_masked = img2\n",
        "\n",
        "\n",
        "    fused = blend_images(img1_masked.convert(\"RGB\"), img2_masked.convert(\"RGB\"), alpha)\n",
        "    fused = sharpen_image(fused, amount=sharpen_amt)\n",
        "    return fused\n",
        "\n",
        "def generate(image1, image2, attribute, alpha, sharpen):\n",
        "    if image1 is None or image2 is None:\n",
        "        return None\n",
        "    im1 = Image.fromarray(image1.astype(np.uint8))\n",
        "    im2 = Image.fromarray(image2.astype(np.uint8))\n",
        "    return fuse_images_with_shape(im1, im2, attribute, alpha=float(alpha), sharpen_amt=float(sharpen))\n",
        "\n",
        "gr.Interface(\n",
        "    fn=generate,\n",
        "    inputs=[\n",
        "        gr.Image(type=\"numpy\", label=\"Image 1\"),\n",
        "        gr.Image(type=\"numpy\", label=\"Image 2\"),\n",
        "        gr.Dropdown(choices=[\"boy kurthys\",\"sheets\",\"t-shirts\",\"women lehenga\",\"sarees\",\"tops\",\"night dress\"],\n",
        "                    label=\"Select Attribute\"),\n",
        "        gr.Slider(0.0, 1.0, 0.5, step=0.05, label=\"Blend Alpha\"),\n",
        "        gr.Slider(0.0, 3.0, 1.5, step=0.1, label=\"Sharpen Amount\")\n",
        "    ],\n",
        "    outputs=gr.Image(type=\"pil\", label=\"Fused & Sharpened Image\"),\n",
        "    title=\"Offline Fashion Fusion with Attribute Shape\",\n",
        "    description=\"Fuses 2 images based on selected fashion attribute and applies attribute-specific shape masks. Fully offline.\"\n",
        ").launch(share=True)\n"
      ],
      "metadata": {
        "id": "zN6illVmNS0z",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 611
        },
        "outputId": "7826de3e-03c1-4eae-e524-2550ccbc8b2b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n",
            "* Running on public URL: https://a74812b50e8c775964.gradio.live\n",
            "\n",
            "This share link expires in 1 week. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://a74812b50e8c775964.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "1RhXWrGVzjvT"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}